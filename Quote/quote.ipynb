{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHRywNU32KhZ"
   },
   "source": [
    "# Assignment 2 - DS4Biz Y63\n",
    "## TextScraping_Classification\n",
    "***\n",
    "\n",
    "### Team Detail\n",
    "**Team Name**: sompinandsomshine   \n",
    "***\n",
    "### *Student 1*\n",
    "**Student ID**: 61070278   \n",
    "**Student Full Name**: นายกิตติภณ สุรุ่งเรืองสกุล\n",
    "***\n",
    "### *Student 2*\n",
    "**Student ID**: 61070330   \n",
    "**Student Full Name**: นางสาวอิงฟ้า ภูติวรนาถ\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx0SQvCq2Khd"
   },
   "source": [
    "#### link: https://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQCUC3SM2Khk"
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1837,
     "status": "ok",
     "timestamp": 1605258507418,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "otwFg1EK2Khm"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "#https://requests.readthedocs.io/en/master/\n",
    "import bs4\n",
    "#https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1825,
     "status": "ok",
     "timestamp": 1605258507421,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "711GJX3y2Khq",
    "outputId": "e499eaf2-3bd1-4192-a987-a10592d1ebbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<class 'requests.models.Response'>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://quotes.toscrape.com/page/1/')\n",
    "print(response)\n",
    "print(type(response))\n",
    "html_page = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "# print(html_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qyrSdr23bYY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "error",
     "timestamp": 1605258796382,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "qKncSUSY2Khu",
    "outputId": "ab86fe20-c0b5-4181-b6f6-67f42e6093af"
   },
   "outputs": [],
   "source": [
    "list_page = []\n",
    "cur = 1\n",
    "while 1:\n",
    "    url = 'https://quotes.toscrape.com/page/'+str(cur)+'/'\n",
    "    response = requests.get(url)\n",
    "    html_page = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "    selector = 'body > div > div:nth-child(2) > div.col-md-8'\n",
    "    tag = html_page.select_one(selector)\n",
    "    if 'No quotes found!' in tag.text:\n",
    "        break\n",
    "    else:\n",
    "        list_page.append(url)\n",
    "        cur += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2247,
     "status": "aborted",
     "timestamp": 1605258507860,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "fq2fOLbm2Khx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://quotes.toscrape.com/page/1/',\n",
       " 'https://quotes.toscrape.com/page/2/',\n",
       " 'https://quotes.toscrape.com/page/3/',\n",
       " 'https://quotes.toscrape.com/page/4/',\n",
       " 'https://quotes.toscrape.com/page/5/',\n",
       " 'https://quotes.toscrape.com/page/6/',\n",
       " 'https://quotes.toscrape.com/page/7/',\n",
       " 'https://quotes.toscrape.com/page/8/',\n",
       " 'https://quotes.toscrape.com/page/9/',\n",
       " 'https://quotes.toscrape.com/page/10/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2238,
     "status": "aborted",
     "timestamp": 1605258507862,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "omR_rhTb2Kh0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>link_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [content, author, tags, link_author]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['content','author','tags', 'link_author'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2236,
     "status": "aborted",
     "timestamp": 1605258507863,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "iqUszuN72Kh4"
   },
   "outputs": [],
   "source": [
    "# Content\n",
    "def extract_content(html_page):\n",
    "    selector = 'div.col-md-8 > div > span.text'\n",
    "    tags = html_page.select(selector)\n",
    "    content = []\n",
    "    \n",
    "    for tag in tags:\n",
    "        content.append(tag.text.strip().replace('“', '').replace('”', ''))\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2236,
     "status": "aborted",
     "timestamp": 1605258507867,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "nqtltEla2Kh8"
   },
   "outputs": [],
   "source": [
    "# Author\n",
    "def extract_author(html_page):\n",
    "    selector = 'div.col-md-8 > div > span > small'\n",
    "    tags = html_page.select(selector)\n",
    "    author = []\n",
    "    \n",
    "    for tag in tags:\n",
    "        author.append(tag.text.strip().replace('-', ' '))\n",
    "        \n",
    "    return author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2236,
     "status": "aborted",
     "timestamp": 1605258507869,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "5cCLJJUL2KiA"
   },
   "outputs": [],
   "source": [
    "# tags\n",
    "def extract_tags(html_page):\n",
    "    selector = 'div.col-md-8 > div > div > meta'\n",
    "    tags = html_page.select(selector)\n",
    "    quote_tags = []\n",
    "    \n",
    "    for tag in tags:\n",
    "#         print(tag['content'])\n",
    "        quote_tags.append(tag['content'])\n",
    "        \n",
    "    return quote_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2234,
     "status": "aborted",
     "timestamp": 1605258507870,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "movHceSQ2KiE"
   },
   "outputs": [],
   "source": [
    "# link_author\n",
    "def extract_link_author(html_page):\n",
    "    selector = 'div.col-md-8 > div > span > a'\n",
    "    tags = html_page.select(selector)\n",
    "    link_author = []\n",
    "    \n",
    "    for tag in tags:\n",
    "#         print(tag['content'])\n",
    "        link_author.append('https://quotes.toscrape.com/author/' + tag['href'].split('/')[-1] + '/')\n",
    "        \n",
    "    return link_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2232,
     "status": "aborted",
     "timestamp": 1605258507872,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "d9nZ_dXQ2KiI"
   },
   "outputs": [],
   "source": [
    "# response = requests.get('https://quotes.toscrape.com/page/1/')\n",
    "# html_page = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# extract_content(html_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2230,
     "status": "aborted",
     "timestamp": 1605258507873,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "7ERJMKwy2KiL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_quotes(url):\n",
    "    response = requests.get(url)\n",
    "    html_page = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    content = extract_content(html_page)\n",
    "    author = extract_author(html_page)\n",
    "    tags = extract_tags(html_page)\n",
    "    link_author = extract_link_author(html_page)\n",
    "    \n",
    "    Alltags = {'content':content,'author':author,'tags':tags,'link_author':link_author}\n",
    "    result = pd.DataFrame(Alltags)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2222,
     "status": "aborted",
     "timestamp": 1605258507875,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "sPG9wZUI2KiO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>link_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The world as we have created it is a process o...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>change,deep-thoughts,thinking,world</td>\n",
       "      <td>https://quotes.toscrape.com/author/Albert-Eins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is our choices, Harry, that show what we tr...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>abilities,choices</td>\n",
       "      <td>https://quotes.toscrape.com/author/J-K-Rowling/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are only two ways to live your life. One...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>inspirational,life,live,miracle,miracles</td>\n",
       "      <td>https://quotes.toscrape.com/author/Albert-Eins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The person, be it gentleman or lady, who has n...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>aliteracy,books,classic,humor</td>\n",
       "      <td>https://quotes.toscrape.com/author/Jane-Austen/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imperfection is beauty, madness is genius and ...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>be-yourself,inspirational</td>\n",
       "      <td>https://quotes.toscrape.com/author/Marilyn-Mon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content           author  \\\n",
       "0  The world as we have created it is a process o...  Albert Einstein   \n",
       "1  It is our choices, Harry, that show what we tr...     J.K. Rowling   \n",
       "2  There are only two ways to live your life. One...  Albert Einstein   \n",
       "3  The person, be it gentleman or lady, who has n...      Jane Austen   \n",
       "4  Imperfection is beauty, madness is genius and ...   Marilyn Monroe   \n",
       "\n",
       "                                       tags  \\\n",
       "0       change,deep-thoughts,thinking,world   \n",
       "1                         abilities,choices   \n",
       "2  inspirational,life,live,miracle,miracles   \n",
       "3             aliteracy,books,classic,humor   \n",
       "4                 be-yourself,inspirational   \n",
       "\n",
       "                                         link_author  \n",
       "0  https://quotes.toscrape.com/author/Albert-Eins...  \n",
       "1    https://quotes.toscrape.com/author/J-K-Rowling/  \n",
       "2  https://quotes.toscrape.com/author/Albert-Eins...  \n",
       "3    https://quotes.toscrape.com/author/Jane-Austen/  \n",
       "4  https://quotes.toscrape.com/author/Marilyn-Mon...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for url in list_page:\n",
    "    result = extract_quotes(url)\n",
    "    df = df.append(result, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2215,
     "status": "aborted",
     "timestamp": 1605258507878,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "N5D2kpqn2KiQ",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content        0\n",
       "author         0\n",
       "tags           0\n",
       "link_author    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StHKFLuG2KiV"
   },
   "source": [
    "## author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2219,
     "status": "aborted",
     "timestamp": 1605258507884,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "gazwMyoF2KiV"
   },
   "outputs": [],
   "source": [
    "# df_author = pd.DataFrame(columns=['Born_date','Born_location','Author_description'])\n",
    "# df_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2219,
     "status": "aborted",
     "timestamp": 1605258507887,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "sBsU3Fu22KiY"
   },
   "outputs": [],
   "source": [
    "# df['Link_author'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2216,
     "status": "aborted",
     "timestamp": 1605258507888,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "2UoX5mmh2Kib"
   },
   "outputs": [],
   "source": [
    "# author born date\n",
    "def born_date(html_page):\n",
    "    born_date = html_page.findAll(\"span\", {\"class\": \"author-born-date\"})\n",
    "    born_date = born_date[0].text.replace(',', '').replace(' ', '-')\n",
    "    return born_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2213,
     "status": "aborted",
     "timestamp": 1605258507890,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "CZFRj1yQ2Kic"
   },
   "outputs": [],
   "source": [
    "# author born location\n",
    "def born_location(html_page):\n",
    "    born_location = html_page.findAll(\"span\", {\"class\": \"author-born-location\"})\n",
    "    born_location = born_location[0].text.replace(',', '|')\n",
    "    return born_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2209,
     "status": "aborted",
     "timestamp": 1605258507891,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "glQD2haA2Kie"
   },
   "outputs": [],
   "source": [
    "# author Description\n",
    "def description(html_page):\n",
    "    description = html_page.findAll(\"div\", {\"class\": \"author-description\"})\n",
    "    description = description[0].text.strip()\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 2206,
     "status": "aborted",
     "timestamp": 1605258507893,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "hKcfwDnj2Kig"
   },
   "outputs": [],
   "source": [
    "# author Description\n",
    "def author_name(html_page):\n",
    "    author_name = html_page.findAll(\"h3\", {\"class\": \"author-title\"})\n",
    "    author_name = author_name[0].text.strip().replace('-', ' ')\n",
    "    return author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 2203,
     "status": "aborted",
     "timestamp": 1605258507895,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "gRydp5q02Kii"
   },
   "outputs": [],
   "source": [
    "# def extract_author(url):\n",
    "#     response = requests.get(url)\n",
    "#     html_page = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     date = born_date(html_page)\n",
    "#     location = born_location(html_page)\n",
    "#     description_text = description(html_page)\n",
    "    \n",
    "#     Alldetail = {'Born_date': date, 'Born_location': location, 'Author_description':description_text}\n",
    "#     result = pd.DataFrame(Alldetail)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2201,
     "status": "aborted",
     "timestamp": 1605258507896,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "tUZvw2632Kik"
   },
   "outputs": [],
   "source": [
    "list_born_date = []\n",
    "list_born_location = []\n",
    "list_description = []\n",
    "list_author_name = []\n",
    "\n",
    "for link_author in list(df['link_author'].unique()):\n",
    "    \n",
    "#     response = requests.get('https://quotes.toscrape.com/author/Albert-Einstein/')\n",
    "    response = requests.get(link_author)\n",
    "    html_page = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    list_born_date.append(born_date(html_page))\n",
    "    list_born_location.append(born_location(html_page))\n",
    "    list_description.append(description(html_page))\n",
    "    list_author_name.append(author_name(html_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2199,
     "status": "aborted",
     "timestamp": 1605258507897,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "LjaDZ38z2Kim",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Alldetail = {'author': list_author_name, 'born_date': list_born_date, 'born_location': list_born_location, 'author_description':list_description}\n",
    "author_df = pd.DataFrame(Alldetail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2191,
     "status": "aborted",
     "timestamp": 1605258507898,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "XXlyZf362Kip"
   },
   "outputs": [],
   "source": [
    "author_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2183,
     "status": "aborted",
     "timestamp": 1605258507899,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "oqtg8nMH2Kis"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2177,
     "status": "aborted",
     "timestamp": 1605258507900,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "QeSG4ybW2Kiu"
   },
   "outputs": [],
   "source": [
    "# df.set_index('Author').join(other.set_index('key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2175,
     "status": "aborted",
     "timestamp": 1605258507901,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "J1B9ifm82Kiw"
   },
   "outputs": [],
   "source": [
    "# result['Author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2169,
     "status": "aborted",
     "timestamp": 1605258507902,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "aM4WEFAG2Kiz"
   },
   "outputs": [],
   "source": [
    "content_author_df = pd.merge(df, author_df, on='author', how='left')\n",
    "content_author_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYrD0LLN2Ki1"
   },
   "source": [
    "## save DataFarame to csv\n",
    "เพื่อให้ง่ายต่อการใช้ในภายหลัง\n",
    "- content.csv รายละเอียดของ quote\n",
    "- author.csv รายละเอียดของผู้เขียน\n",
    "- content_author.csv รายละเอียดของ quote และผู้เขียน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2167,
     "status": "aborted",
     "timestamp": 1605258507904,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "WM-B0u-_2Ki2"
   },
   "outputs": [],
   "source": [
    "df.to_csv('content.csv', index=False)\n",
    "author_df.to_csv('author.csv', index=False)\n",
    "content_author_df.to_csv('content_author.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2158,
     "status": "aborted",
     "timestamp": 1605258507904,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "BMMrV_ZN2Ki3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('content.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2149,
     "status": "aborted",
     "timestamp": 1605258507905,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "Cpk7jyHo2Ki6"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2144,
     "status": "aborted",
     "timestamp": 1605258507906,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "k-z2MRVA2Ki9"
   },
   "outputs": [],
   "source": [
    "df[df['tags'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2140,
     "status": "aborted",
     "timestamp": 1605258507906,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "vQjv-8wq2Ki-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlZ_5-NV2KjB"
   },
   "source": [
    "### บันทึก tags\n",
    "folder target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2133,
     "status": "aborted",
     "timestamp": 1605258507907,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "rFlC9kUP2KjB"
   },
   "outputs": [],
   "source": [
    "df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2132,
     "status": "aborted",
     "timestamp": 1605258507908,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "stZnZ_Tp2KjD"
   },
   "outputs": [],
   "source": [
    "df['tags'].to_csv(r'target/tags.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 2131,
     "status": "aborted",
     "timestamp": 1605258507909,
     "user": {
      "displayName": "ENGFAH PUTIVARANAT",
      "photoUrl": "",
      "userId": "14896843217925999521"
     },
     "user_tz": -420
    },
    "id": "CmW1bEwU2KjG"
   },
   "source": [
    "แง้ว"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['tags'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "tags_new = []\n",
    "for i in df['tags']:\n",
    "    tags_new.append(i.split(',')) #for each tags cell, create a list of items from the original string, using a comma as a delimeter\n",
    "    \n",
    "#add new tags column to the dataframe\n",
    "df['tags_new'] = tags_new \n",
    "\n",
    "## MultiLabelBinarizer takes an iterable list and turns it into columns with binary values that represent the list.\n",
    "## For example, [Comedy, Drama] -> Comedy and Drama columns with a value of 1, all other columns with a value of 0\n",
    "\n",
    "#initialize MultiLabelBinarizer \n",
    "mlb = MultiLabelBinarizer() \n",
    "\n",
    "#transform the tags_new column to a series of columns with binary values\n",
    "binary_labels = pd.DataFrame(mlb.fit_transform(df['tags_new']),columns=mlb.classes_) \n",
    "\n",
    "\n",
    "#order columns alphabetically\n",
    "binary_labels = binary_labels.sort_index(axis=1) \n",
    "\n",
    "binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_labels.to_csv(r'target/binary_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Drop non-properly formatted columns\n",
    "# df_all = df_all.drop(columns=['author', 'link_author','tags_new'])\n",
    "# df_all.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict = {}\n",
    "# รัน for loop เพื่อเก็บ tags และจำนวนที่เจอ ไว้ใน dict\n",
    "for column in binary_labels:\n",
    "    sum_num = binary_labels[column].sum(axis=0)\n",
    "    tags_dict.update({column : sum_num})\n",
    "    \n",
    "# sort dict\n",
    "sort_tags_dict = {k: v for k, v in sorted(tags_dict.items(), key=lambda item: item[1], reverse = True)};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags ที่มีเยอะสุด 15 tags แรก\n",
    "top15_tags = list(sort_tags_dict)[:15]\n",
    "top15_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = top15_tags\n",
    "y = []\n",
    "for i in top15_tags:\n",
    "    y.append(sort_tags_dict[i])\n",
    "\n",
    "sns.set(font_scale = 3)\n",
    "plt.figure(figsize=(55,28))\n",
    "ax = sns.barplot(x, y)\n",
    "plt.title(\"Tags having multiple labels Top 15\", fontsize=50)\n",
    "plt.ylabel('Frequency', fontsize=35)\n",
    "plt.xlabel('Name of tags', fontsize=35)\n",
    "\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = y\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height+1/5, label, ha='center', va='bottom', fontsize=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring data frames together\n",
    "df_all = df.merge(binary_labels, how='inner', left_index=True, right_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select column\n",
    "df_all = df_all[[\"content\", \"tags\"] + top15_tags]\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### คัดให้เหลือเฉพาะที่ใช้ในการวิเคราะห์\n",
    "- AllArticles_OnlyHeading\n",
    "- AllArticles_OnlyContent\n",
    "- AllArticles_HeadingPlusContent\n",
    "- Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllArticles_OnlyHeading = df['title']\n",
    "AllArticles_OnlyContent = df_all['content']\n",
    "# AllArticles_HeadingPlusContent = df_all[['title','content']]\n",
    "tags = df_all['tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllArticles_OnlyHeading.to_csv('datastore/AllArticles_OnlyHeading.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllArticles_OnlyContent.to_csv('datastore/AllArticles_OnlyContent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllArticles_HeadingPlusContent.to_csv('datastore/AllArticles_HeadingPlusContent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.to_csv('target/tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllArticles_OnlyHeading.to_csv(r'AllArticles_OnlyHeading.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllArticles_OnlyContent.to_csv(r'AllArticles_OnlyContent.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AllArticles_HeadingPlusContent.to_csv(r'AllArticles_HeadingPlusContent.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.to_csv(r'target/tags.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels.to_csv(r'target/tags3.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------Tokenizer and WordNet Lemmatizer with POS (part of speech)--------------------------------------\n",
    "def lemma_tokenizer_w_pos_tag(text):\n",
    "    # define a nested function for converting POS tag for Lemmatizer\n",
    "    def convert_tags(tag):\n",
    "        if tag == 'vbd' or tag == 'vbg' or tag == 'vbz':\n",
    "            return 'v'\n",
    "        else: \n",
    "            return 'n'\n",
    "    \n",
    "    #-----------------------------------------------Using WordNet Lemmatizer-----------------------------------------\n",
    "    # use the standard scikit-learn tokenizer first\n",
    "    standard_tokenizer = CountVectorizer().build_tokenizer()\n",
    "    tokens = standard_tokenizer(text)\n",
    "    tokens_with_pos_tag = nltk.pos_tag(tokens)\n",
    "\n",
    "    # then use NLTK to perform lemmatisation on each token\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemma_tokens = []\n",
    "    for token in tokens_with_pos_tag:\n",
    "        new_tag = convert_tags(token[1].lower())\n",
    "        lemma_tokens.append(lemmatizer.lemmatize(token[0], new_tag))\n",
    "    \n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(\"AllArticles_OnlyContent.txt\",\"r\", encoding=\"utf8\")\n",
    "raw_documents = fin.readlines()\n",
    "fin.close()\n",
    "print(\"Read %d raw text documents\" % len(raw_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"datastore/AllArticles_OnlyContent.txt\",\"r\", encoding=\"utf8\") as f:\n",
    "#     raw_documents = f.read().splitlines() #ใช้แยก string ที่จุดขึ้นบรรทัดใหม่คือ จุดที่มี '\\n' แล้วคืนค่ากลับมาเป็นข้อมูลประเภท list\n",
    "# f.close()\n",
    "# print(\"Read %d raw text documents\" % len(raw_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_tokenizer_w_pos_tag(df_all['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all['love'][1]\n",
    "df_all.columns[2::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def y_tags()\n",
    "# for j in range(94):\n",
    "#     for i in df_all.columns[2::]:\n",
    "#         print(df_all[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">K-Nearest Neighbors<span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_data(tags_name):\n",
    "    x = df_all['content']\n",
    "#     x = raw_documents\n",
    "    y = df_all[tags_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.1) #, shuffle=True\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_data('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=\"english\",min_df = 0,tokenizer=lemma_tokenizer_w_pos_tag)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "]).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3),min_df = 0, \n",
    "                             stop_words = 'english', sublinear_tf=True, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'n_neighbors' : list(np.arange(1,50,2)),\n",
    "    'weights' : ['uniform', 'distance'], \n",
    "    'metric' : ['euclidean', 'manhattan'] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunning parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy_knn_list = []\n",
    "precision_knn_list = []\n",
    "recall_knn_list = []\n",
    "\n",
    "for tags_name in top15_tags:\n",
    "    X_train, X_test, y_train, y_test = train_test_data(tags_name)\n",
    "    X_train = pipe.transform(X_train)\n",
    "    X_new_tfidf = pipe.transform(X_test)\n",
    "\n",
    "#     folds = 5 \n",
    "    knn = KNeighborsClassifier() \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 1001) \n",
    "    knn_grid = GridSearchCV(knn, params, verbose = 3, cv=skf.split(X_train,y_train), n_jobs = -1)\n",
    "    knn_grid.fit(X_train, y_train);\n",
    "#     print(knn_grid.best_params_)\n",
    "#     k_list.append(knn_grid.best_params_['n_neighbors'])\n",
    "    \n",
    "    \n",
    "    knn=KNeighborsClassifier(metric=knn_grid.best_params_['metric'], \n",
    "                             n_neighbors=knn_grid.best_params_['n_neighbors'], \n",
    "                             weights=knn_grid.best_params_['weights'])\n",
    "    knn.fit(X_train, y_train)\n",
    "    cv = LeaveOneOut()\n",
    "    scores = cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=cv, n_jobs = -1)\n",
    "    accuracy_knn_list.append(mean(scores))\n",
    "    print('%s -> Accuracy: %.3f (%.3f)' % (tags_name ,mean(scores), std(scores)))\n",
    "    \n",
    "    knn_pred = knn.predict(X_new_tfidf)\n",
    "    precision = metrics.precision_score(y_test, knn_pred, average='macro')\n",
    "    precision_knn_list.append(precision)\n",
    "    print('Precision Score: %.3f' % precision)\n",
    "    \n",
    "    recall = metrics.recall_score(y_test, knn_pred, average='macro')\n",
    "    recall_knn_list.append(recall)\n",
    "    print('recall Score: %.3f' % recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_knn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Tags': np.array(top15_tags), 'Accuracy': np.array(accuracy_knn_list), \n",
    "        'Precision': np.array(precision_knn_list), 'Recall': np.array(recall_knn_list)}\n",
    "df_knn = pd.DataFrame(data=data)\n",
    "df_knn = df_knn.sort_values(by=['Precision'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# เพิ่ม Row ที่เป็นค่าเฉลี่ยของ Accuracy\n",
    "df_knn = df_knn.append({'Tags' : 'Average' , \n",
    "                        'Accuracy' : (sum(accuracy_knn_list)/15), \n",
    "                        'Precision' : (sum(precision_knn_list)/15),\n",
    "                        'Recall': (sum(recall_knn_list)/15)}, ignore_index=True)\n",
    "\n",
    "# highlight row in Dataframe\n",
    "color = (df_knn['Tags'] == 'Average').map({True: 'background-color: yellow', False: ''})\n",
    "df_knn.style.apply(lambda s: color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Tunning parameter (weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "accuracy_knn_list = []\n",
    "precision_knn_list = []\n",
    "recall_knn_list = []\n",
    "\n",
    "for tags_name in top15_tags:\n",
    "    X_train, X_test, y_train, y_test = train_test_data(tags_name)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_new_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    folds = 5 \n",
    "    knn = KNeighborsClassifier() \n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001) \n",
    "    knn_grid = GridSearchCV(knn, params, verbose = 3, cv=skf.split(X_train,y_train), n_jobs = -1)\n",
    "    knn_grid.fit(X_train, y_train);\n",
    "#     print(knn_grid.best_params_)\n",
    "#     k_list.append(knn_grid.best_params_['n_neighbors'])\n",
    "    \n",
    "    \n",
    "    knn=KNeighborsClassifier(metric=knn_grid.best_params_['metric'], \n",
    "                             n_neighbors=knn_grid.best_params_['n_neighbors'], \n",
    "                             weights=knn_grid.best_params_['weights'])\n",
    "    knn.fit(X_train, y_train)\n",
    "    cv = LeaveOneOut()\n",
    "    scores = cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=cv, n_jobs = -1)\n",
    "    accuracy_knn_list.append(mean(scores))\n",
    "    print('%s -> Accuracy: %.3f (%.3f)' % (tags_name ,mean(scores), std(scores)))\n",
    "    \n",
    "    knn_pred = knn.predict(X_new_tfidf)\n",
    "    precision = metrics.precision_score(y_test, knn_pred, average='macro')\n",
    "    precision_knn_list.append(precision)\n",
    "    print('Precision Score: %.3f' % precision)\n",
    "    \n",
    "    recall = metrics.recall_score(y_test, knn_pred, average='macro')\n",
    "    recall_knn_list.append(recall)\n",
    "    print('recall Score: %.3f' % recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Tags': np.array(top15_tags), 'Accuracy': np.array(accuracy_knn_list), \n",
    "        'Precision': np.array(precision_knn_list), 'Recall': np.array(recall_knn_list)}\n",
    "df_knn = pd.DataFrame(data=data)\n",
    "df_knn = df_knn.sort_values(by=['Precision'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# เพิ่ม Row ที่เป็นค่าเฉลี่ยของ Accuracy\n",
    "df_knn = df_knn.append({'Tags' : 'Average' , \n",
    "                        'Accuracy' : (sum(accuracy_knn_list)/15), \n",
    "                        'Precision' : (sum(precision_knn_list)/15),\n",
    "                        'Recall': (sum(recall_knn_list)/15)} , ignore_index=True)\n",
    "\n",
    "# highlight row in Dataframe\n",
    "color = (df_knn['Tags'] == 'Average').map({True: 'background-color: yellow', False: ''})\n",
    "df_knn.style.apply(lambda s: color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "quote.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
